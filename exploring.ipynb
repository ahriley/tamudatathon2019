{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAMU Datathon: Taco/Burrito Challenge\n",
    "\n",
    "### Team Name: Taco 'Bout It!\n",
    "### Team Members: Alex Riley, Jacqueline Antwi-Danso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to participate in the Goldman Sachs data challenge, which centers on a dataset logging taco and burrito menu items in the United States ([Kaggle link](https://www.kaggle.com/datafiniti/restaurants-burritos-and-tacos/)). The tasks of the challenge are:\n",
    "\n",
    "```\n",
    "The final product of your efforts should include a visualization of your output, with supporting documentation detailing the modeling and analysis performed.\n",
    "```\n",
    "\n",
    "We'll start with the usual Python imports, plus some that will be useful for data cleaning (dealing with zip codes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from uszipcode import SearchEngine\n",
    "import plotly.graph_objects as go\n",
    "%matplotlib inline\n",
    "\n",
    "# so plotly map can render\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# contains mappings between state name and abbreviation\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'data/just-tacos-and-burritos.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of unnamed columns that are filled with `NaN`. Let's get rid of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = data.isna().sum() == len(data)\n",
    "assert np.array([\"Unnamed\" in col for col in data.columns[empty]]).all()\n",
    "data.drop(columns=data.columns[empty], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of columns\n",
    "\n",
    "* `id`: unique ID for restaurant\n",
    "* `address`: restaurant address (number and street name)\n",
    "* `categories`: categories for restaurant (e.g. \"Restaurant\" or \"Restaurant Delivery\")\n",
    "* `city`: city name\n",
    "* `country`: country (note: all are in the US)\n",
    "* `cuisines`: type of restaurant, e.g. \"Coffee\" or \"Mexican\". Not unique (one example is \"Buffets, Pizza\")\n",
    "* `dateAdded`: date that entry was added to dataset\n",
    "* `dateUpdated`: date that entry was last updated (can be equal to `dateAdded`)\n",
    "* `keys`: ???\n",
    "* `latitude`: latitude of the restaurant\n",
    "* `longitude`: longitude of the restaurant\n",
    "* `menuPageURL`: URL to menu\n",
    "* `menus.amountMax`: max amount on menu? (sparsely filled; 37,000 NaN)\n",
    "* `menus.amountMin`: min amount on menu? (sparsely filled; 37,000 NaN)\n",
    "* `menus.category`: category that item falls under in menu (e.g. \"Main Course\", \"Tacos\"). Sparsely filled, 73,531 NaN\n",
    "* `menus.currency`: currency used on item. usually USD, 16 entries are EUR\n",
    "* `menus.dateseen`: date that menu was observed\n",
    "* `menus.description`: description of item in menu\n",
    "* `name`: name of restaurant\n",
    "* `postalCode`: ZIP code of restaurant\n",
    "* `priceRangeCurrency`: currency used for `menus.priceRangeMin/Max` usually USD, one entry in AUD\n",
    "* `priceRangeMin`: minimum price of items on menu\n",
    "* `priceRangeMax`: maximum price of items on menu\n",
    "* `province`: typically state but not always. needs cleaning\n",
    "* `websites`: website for the restaurant\n",
    "\n",
    "### Potential data cleaning issues\n",
    "* `name` can have multiple values, like `McDonald's` and `Mc Donalds`\n",
    "* many columns are incomplete, including `postalCode` and `latitude/longitude` which might make analysis/visualizing the spatial distribution of restaurants difficult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "Consistent identification of city + state (`province` is not clean version of this). We'll start off by creating a new column named `state`.\n",
    "\n",
    "**Note: this section can be skipped if it's already been run once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['state'] = data['province']\n",
    "\n",
    "# three entries had no province info, all were in San Francisco\n",
    "data.loc[data['state'].isna(), 'state'] = 'CA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a few freebies. These were common (top 25-ish) values for `province` that are easily mapped to states, as well as `province` values that were 2 characters that did not match state abbreviation codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['state'] == 'California', 'state'] = 'CA'\n",
    "data.loc[data['state'] == 'Manhattan', 'state'] = 'NY'\n",
    "data.loc[data['state'] == 'New York City', 'state'] = 'NY'\n",
    "data.loc[data['state'] == 'Ny', 'state'] = 'NY'\n",
    "data.loc[data['state'] == 'Ls', 'state'] = 'MO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pops that remain would be a pain to continue for. For these ~8000 pops, we will use the `uszipcode` package to map provided zip codes to the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badmask = data['state'].apply(len) != 2\n",
    "search = SearchEngine()\n",
    "data.loc[badmask, 'state'] = data[badmask].apply(lambda x: search.by_zipcode(x['postalCode']).state if x['postalCode'] else x['state'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're done! We can check that all of the `state` items are valid state codes by cross-referencing against the list located in `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['state'].apply(lambda x: True if x in utils.abbrev_us_state else False).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['citystate'] = data.apply(lambda x: x['city']+', '+x['state'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question: Where are the authentic Mexican restaurants?\n",
    "\n",
    "## Marking out \"authentic\"\n",
    "\n",
    "We want to exclude stores that can be reliably marked as \"inauthentic,\" like Subway or McDonald's. For this, we'll exclude any restaurants from this list of the [32 biggest fast food chains in America](https://www.qsrmagazine.com/content/32-biggest-fast-food-chains-america). We also opt to include Chili's in the list of excluded chains.\n",
    "\n",
    "Notice, some names have permutations that match names occurring in top 100 (e.g. McDonald's)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chains_mask(data):\n",
    "    exclude_list = [\"Subway\", \"Starbucks\",\n",
    "                \"McDonald's\", \"Mcdonald's\", \"Mc Donald's\", \"Mcdonalds\", \"McDonalds\",\n",
    "                \"Dunkin\", \"Pizza Hut\", \"Burger King\", \"Wendy's\", \"Taco Bell\",\n",
    "                \"Domino's\", \"Dairy Queen\", \"Little Caesars\", \"KFC\",\n",
    "                \"Sonic Drive In\", \"SONIC Drive In\", \"Sonic Drive-in\", \"Sonic Drive-In\",\n",
    "                \"Papa John's\", \"Arby's\", \"Jimmy John's\",\n",
    "                \"Baskin-Robbins\", \"Chipotle Mexican Grill\", \"Chick-Fil-A\", \"Popeye's\",\n",
    "                \"Jack in the Box\", \"Jack In The Box\",\n",
    "                \"Panda Express\", \"Panera\", \"Carl's Jr.\", \"Jersey Mike's\", \"Papa Murphy's\",\n",
    "                \"Five Guys\", \"Auntie Anne's\", \"Wingstop\", \"Firehouse Subs\"]\n",
    "\n",
    "    # also exclude Chili's\n",
    "    exclude_list.append(\"Chili's Grill & Bar\")\n",
    "    exclude_list.append(\"Chili's Grill Bar\")\n",
    "    exclude_list.append(\"Chili's\")\n",
    "    exclude_list.append(\"Chili's Too\")\n",
    "\n",
    "    chain = [False] * len(data)\n",
    "    for name in exclude_list:\n",
    "        chain |= data['name'] == name\n",
    "    \n",
    "    return ~chain\n",
    "\n",
    "authentic = data[chains_mask(data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are interested in the question where are authentic **restaurants** concentrated in the U.S.? For this, we need to only have a list of authentic restaurants, not a list of authentic burritos/tacos. Luckily, we can just mask duplicated `id`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_restaurant_mask = ~authentic['id'].duplicated()\n",
    "restaurants = authentic[unique_restaurant_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get a very simple answer for which cities host the most authentic Mexican restaurants in the U.S.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citycounts = restaurants['citystate'].value_counts()\n",
    "citycounts.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this just looks like a list of big cities with a lot of people (who would therefore have a lot of authentic Mexican restaurants). To fix this, we can instead try to get the number of restaurants _per capita_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For population data, we'll use [population estimates from the U.S. Census Bureau](https://www.census.gov/data/tables/time-series/demo/popest/2010s-total-cities-and-towns.html#ds) for 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popfile = 'data/sub-est2018_all.csv'\n",
    "popdata = pd.read_csv(popfile, encoding=\"ISO-8859-1\")\n",
    "popdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we simply need to find a city by matching the city name and state in the `popdata` table. We also need to convert the state code (e.g. \"AL\") to a state name (\"Alabama\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = []\n",
    "for name, pop in citycounts.iteritems():\n",
    "    match = popdata['NAME'] == name[:-4] + ' city'\n",
    "    match |= popdata['NAME'] == name[:-4] + ' town'\n",
    "    match |= popdata['NAME'] == name[:-4] + ' village'\n",
    "    match &= popdata['STNAME'] == utils.abbrev_us_state[name[-2:]]\n",
    "    pop = np.max(popdata[match]['POPESTIMATE2018'])\n",
    "    population.append(pop)\n",
    "population = np.array(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citycounts_percapita = (citycounts/population) * 1000\n",
    "citycounts_percapita.sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these are the places that have a lot of authentic Mexican restaurants relative to how big their population is. However, all of these places are very small and isolated. Let's place a cut on the data requiring a population of over 50,000 (the high end of what is considered the threshold for a \"city\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 50000\n",
    "citycounts_percapita[population > threshold].sort_values(ascending=False).head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be (somewhat) expected, the list is now dominated by cities in California (with one entry from New Mexico)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: where are the tacos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = data['city'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def food_nums(loc_arr):\n",
    "    df = data\n",
    "    tacos = []; burritos = []\n",
    "    for name in loc_arr:\n",
    "        menu_options = df[df['city'] == name]['menus.name']\n",
    "        \n",
    "        # for each restaurant in each city, calculate the number of burritos and tacos \n",
    "        num_tacos = []\n",
    "        num_burritos = []\n",
    "        for option in menu_options: \n",
    "             \n",
    "            if \"Taco\" in option:\n",
    "                num_tacos.append(1)\n",
    "            \n",
    "            if \"Burrito\" in option:\n",
    "                num_burritos.append(1)\n",
    "            \n",
    "        if len(num_tacos) != 0:\n",
    "            total_tacos = np.sum(num_tacos)\n",
    "        else:\n",
    "            total_tacos = 0\n",
    "        if len(num_burritos) != 0:\n",
    "            total_burritos = np.sum(num_burritos)\n",
    "        else: \n",
    "            total_burritos = 0\n",
    "           \n",
    "        tacos.append(total_tacos)\n",
    "        burritos.append(total_burritos)\n",
    "        \n",
    "    return tacos, burritos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tacos, num_burritos = food_nums(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn zeros into very big/small numbers to avoid to avoid division by 0\n",
    "num_tacos = np.array(num_tacos)\n",
    "num_burritos = np.array(num_burritos)\n",
    "\n",
    "tmp_num_tacos = np.copy(num_tacos)\n",
    "tmp_num_burritos = np.copy(num_burritos)\n",
    "\n",
    "tmp_num_tacos[tmp_num_tacos == 0] = -1\n",
    "tmp_num_burritos[tmp_num_burritos == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_ratio = tmp_num_burritos/tmp_num_tacos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_ratio[city_ratio < 0] = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique lon and lat for each city \n",
    "lon = []; lat = []\n",
    "for city in cities:\n",
    "        lon.append(np.unique(data[data['city'] == city]['longitude'])[0])\n",
    "        lat.append(np.unique(data[data['city'] == city]['latitude'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming because plotly has similar keyword \n",
    "lon_arr = np.copy(lon); lat_arr = np.copy(lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_cities = np.array(cities)[~np.isinf(city_ratio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_arr = [city + '\\n B/T:' + str(np.round_(num, decimals = 2)) for city, num in zip(cities, city_ratio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "limits = [(0,3),(4,7),(8,11),(12,15),(16,20)]\n",
    "colors = [\"brown\",\"magenta\",\"cyan\",\"orange\",\"green\"]\n",
    "\n",
    "for i in range(len(limits)):\n",
    "    lim = limits[i]\n",
    "    fig.add_trace(go.Scattergeo(\n",
    "        locationmode = 'USA-states',\n",
    "        lon = lon_arr,\n",
    "        lat = lat_arr,\n",
    "        text = text_arr,\n",
    "        marker = dict(\n",
    "            size = city_ratio*5,\n",
    "            color = colors[i],\n",
    "            sizemode = 'area', \n",
    "        ),\n",
    "        name = '{0} - {1}'.format(lim[0],lim[1])))\n",
    "    \n",
    "fig.update_layout(\n",
    "        #title_text = 'Menu options by city <br>(Click legend to populate map)',\n",
    "        title_text = 'Menu options by city <br>(Hover on point to see burrito/taco ratio)',\n",
    "        showlegend = False,\n",
    "        geo = dict(\n",
    "            scope = 'usa',\n",
    "            landcolor = 'rgb(217, 217, 217)',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
